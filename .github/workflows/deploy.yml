# .github/workflows/deploy.yml
# TEST  2
name: Deploy ideal_next_js

on:
  push:
    branches: [ new-ver ]

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: eu-north-1
  ROLE_ARN: arn:aws:iam::551829622535:role/githubrepoIdealtax
  SUBDIR: nextjs-clone
  APP_NAME: ideal_next_js
  DEPLOY_TAG_KEY: Deploy
  DEPLOY_TAG_VAL: Yes

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      # Find EC2 instances with Deploy=Yes and confirm SSM sees them
      - name: Discover instance(s) by tag and confirm SSM
        id: discover
        run: |
          set -euo pipefail
          echo "Region: ${AWS_REGION}"
          echo "Tag: ${DEPLOY_TAG_KEY}=${DEPLOY_TAG_VAL}"

          IDS=$(aws ec2 describe-instances \
            --region "${AWS_REGION}" \
            --filters "Name=tag:${DEPLOY_TAG_KEY},Values=${DEPLOY_TAG_VAL}" "Name=instance-state-name,Values=running" \
            --query 'Reservations[].Instances[].InstanceId' \
            --output text)

          echo "EC2 IDs: ${IDS:-<none>}"

          if [ -n "${IDS}" ]; then
            echo "SSM-managed nodes among those IDs:"
            aws ssm describe-instance-information \
              --region "${AWS_REGION}" \
              --filters "Key=InstanceIds,Values=${IDS}" \
              --query 'InstanceInformationList[].{Id:InstanceId,Ping:PingStatus,Tags:Tags}' \
              --output table
            # Keep only SSM-managed IDs (Ping online/offline both okay for targeting)
            SSM_IDS=$(aws ssm describe-instance-information \
              --region "${AWS_REGION}" \
              --filters "Key=InstanceIds,Values=${IDS}" \
              --query 'InstanceInformationList[].InstanceId' \
              --output text)
          else
            SSM_IDS=""
          fi

          echo "SSM IDs: ${SSM_IDS:-<none>}"
          echo "ids=${SSM_IDS}" >> "$GITHUB_OUTPUT"

          if [ -z "${SSM_IDS}" ]; then
            echo "::error::No SSM-managed instances found for tag ${DEPLOY_TAG_KEY}=${DEPLOY_TAG_VAL} in ${AWS_REGION}."
            exit 1
          fi

      # Send the deploy script to those instances via SSM
# replace your current "Send SSM deploy command" step with this:
      - name: Send SSM deploy command (pull & rebuild only if needed)
        id: send_cmd
        env:
          INST_IDS: ${{ steps.discover.outputs.ids }}
        run: |
          set -euo pipefail
          echo "Target instance IDs: ${INST_IDS}"

          # -- The bash that will run on EC2 via SSM --
          CMD=$(cat <<'BASH'
          #!/usr/bin/env bash
          set -Eeuo pipefail

          APP_USER="ubuntu"
          APP_ROOT="/srv/ideal_next_js"
          SUBDIR="nextjs-clone"
          SERVICE_NAME="ideal_next_js"
          BRANCH="new-ver"
          REPO_URL="https://github.com/kareou/ideal_next_js"

          cd "$APP_ROOT"

          # 1) Ensure repo exists, or clone shallow once
          if [ ! -d ".git" ]; then
            echo "First-time clone..."
            sudo -u "$APP_USER" git clone --branch "$BRANCH" --depth=1 "$REPO_URL" "$APP_ROOT"
            sudo chown -R "$APP_USER":"$APP_USER" "$APP_ROOT"
          fi

          # Git safety (Ubuntu + sudo sometimes needs this)
          git config --global --add safe.directory "$APP_ROOT"

          # 2) Record current package-lock hash (if any)
          LOCK_BEFORE=""
          if [ -f "$APP_ROOT/$SUBDIR/package-lock.json" ]; then
            LOCK_BEFORE=$(sha256sum "$APP_ROOT/$SUBDIR/package-lock.json" | awk '{print $1}')
          fi

          # 3) Fetch only changes and reset
          echo "Fetching updates..."
          sudo -u "$APP_USER" git fetch origin "$BRANCH" --depth=1
          sudo -u "$APP_USER" git checkout "$BRANCH" || true
          sudo -u "$APP_USER" git reset --hard "origin/$BRANCH"

          # 4) Decide if we must reinstall: package-lock changed?
          LOCK_AFTER=""
          if [ -f "$APP_ROOT/$SUBDIR/package-lock.json" ]; then
            LOCK_AFTER=$(sha256sum "$APP_ROOT/$SUBDIR/package-lock.json" | awk '{print $1}')
          fi

          cd "$APP_ROOT/$SUBDIR"

          # 5) Keep Next cache for faster builds (not tracked by git)
          export NEXT_TELEMETRY_DISABLED=1
          # You can also persist cache elsewhere and symlink if you want:
          # PERSIST="/srv/ideal_next_js/.next-cache"
          # mkdir -p "$PERSIST" && rm -rf .next/cache && ln -s "$PERSIST" .next/cache

          # 6) Install only when lock changed, otherwise skip
          if [ "$LOCK_BEFORE" != "$LOCK_AFTER" ]; then
            echo "package-lock.json changed -> npm ci --omit=dev"
            sudo -u "$APP_USER" npm ci --omit=dev
          else
            echo "package-lock.json unchanged -> skipping npm ci"
          fi

          # 7) Build (uses .next/cache, so itâ€™s incremental & faster)
          echo "Running next build..."
          sudo -u "$APP_USER" npm run build

          # 8) Restart the service
          echo "Restarting service..."
          systemctl daemon-reload
          systemctl restart "$SERVICE_NAME"
          systemctl status "$SERVICE_NAME" --no-pager || true
          BASH
          )

          CMD_ID=$(aws ssm send-command \
            --document-name "AWS-RunShellScript" \
            --instance-ids ${INST_IDS} \
            --parameters commands="[$(printf '%s' "$CMD" | jq -Rs .)]" \
            --query Command.CommandId --output text)

          echo "CommandId: $CMD_ID"
          echo "command_id=$CMD_ID" >> "$GITHUB_OUTPUT"

      # Robust waiter: prints stdout/stderr and fails on non-success
      - name: Wait for SSM command to complete & print output
        env:
          REGION: ${{ env.AWS_REGION }}
          INST_IDS: ${{ steps.discover.outputs.ids }}
          CMD_ID: ${{ steps.send_cmd.outputs.command_id }}
        run: |
          set -Eeuo pipefail
          echo "CMD_ID=${CMD_ID}"
          echo "INST_IDS=${INST_IDS}"

          # Only handle the first instance id for output (extend to loop if you target many)
          INST_ID=$(echo "${INST_IDS}" | awk '{print $1}')
          echo "Inspecting instance: ${INST_ID}"

          sleep 5

          for i in $(seq 1 720); do
            OUT=$(aws ssm get-command-invocation \
              --region "$REGION" \
              --command-id "$CMD_ID" \
              --instance-id "$INST_ID" 2>&1 || true)

            if echo "$OUT" | grep -q 'InvocationDoesNotExist'; then
              echo "Status: not-ready (InvocationDoesNotExist)"
              sleep 5
              continue
            fi

            STATUS=$(echo "$OUT" | jq -r '.Status // empty')
            if [ -z "$STATUS" ]; then
              echo "Raw response:"
              echo "$OUT"
              sleep 5
              continue
            fi

            echo "Status: $STATUS"
            if [ "$STATUS" = "Pending" ] || [ "$STATUS" = "InProgress" ]; then
              sleep 5
              continue
            fi

            # Terminal state: print outputs
            echo "$OUT" | jq '{Status, StandardOutputContent, StandardErrorContent}'
            test "$STATUS" = "Success"
            exit 0
          done

          echo "::error::Timed out waiting for SSM command to complete."
          echo "Command summary:"
          aws ssm list-commands --region "$REGION" --command-id "$CMD_ID" --output table || true
          echo "Invocations:"
          aws ssm list-command-invocations --region "$REGION" --command-id "$CMD_ID" --details --output table || true
          exit 1
